{"cells":[{"cell_type":"markdown","metadata":{"id":"KyKt9ghcu1lX"},"source":["# Getting started with authentication and package installation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FTHFRdWCu226"},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aYEwJAuMLg0f"},"outputs":[],"source":["!earthengine authenticate\n","import ee\n","ee.Initialize()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUzcfAlQVaxJ"},"outputs":[],"source":["import subprocess\n","try:\n","  import geemap\n","except ImportError:\n","  print('geemap package not installed. Installing ...')\n","  subprocess.check_call([\"python\", '-m', 'pip', 'install', 'geemap'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9jYSc3U5GVj"},"outputs":[],"source":["!pip install geopandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VFb68uSVd6j"},"outputs":[],"source":["import geemap\n","import geopandas as gpd\n","import os\n","import glob\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"s3qCeYS8vAnD"},"source":["# Prepare datasets for extracting raster value with buffered points"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uUsunVvUGkUS"},"outputs":[],"source":["# Import datasets; soil, terrain, and LULC were handled in GEE so not repeated here; however, they may be processed in Colab if GEE capacity was exceeded\n","# Alternative Landsat and MODIS datasets may be used depending on the scale and resolution of interests\n","DAYMET = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\")\n","NDWI = ee.ImageCollection(\"MODIS/MOD09GA_006_NDWI\")\n","MODISTree = ee.ImageCollection(\"MODIS/006/MOD44B\")\n","MODISGPP = ee.ImageCollection(\"MODIS/006/MOD17A2H\")\n","MODISEVI = ee.ImageCollection(\"MODIS/MOD09GA_006_EVI\")\n","MODISLST = ee.ImageCollection('MODIS/006/MOD11A1')\n","siteyear = ee.FeatureCollection(\"users/username/Moisture/site_year\")\n","sitedate = ee.FeatureCollection(\"users/username/Moisture/Site_date\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_DcMKs3YRMR"},"outputs":[],"source":["# Climate data processing\n","precipitation = DAYMET.select(\"prcp\")\n","airTmin = DAYMET.select(\"tmin\")\n","airTmax = DAYMET.select(\"tmax\")\n","vpd = DAYMET.select(\"vp\")"]},{"cell_type":"markdown","source":["# Use loop function to automatically extract all covariates"],"metadata":{"id":"R9OgIfI3oMFi"}},{"cell_type":"code","source":["# Define output directory\n","out_dir = os.path.expanduser('.')\n","if not os.path.exists(out_dir):\n","    os.makedirs(out_dir)"],"metadata":{"id":"aEivuMOCoT3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define function for automatic extraction\n","def Extresult(i):\n","   ppt = precipitation.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date_filtered['Date'].get(i)))).first();\n","   Tmin = airTmin.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date_filtered['Date'].get(i)))).first();\n","   Tmax = airTmax.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date_filtered['Date'].get(i)))).first();\n","   Tmean = Tmin.add(Tmax).divide(2).rename(\"tavg\");\n","   VPD = vpd.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date_filtered['Date'].get(i)))).first();\n","   modisndwi = NDWI.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date_filtered['Date'].get(i)))).first().rename(\"ndwi\");\n","   modisgpp = MODISGPP.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date_filtered['Date'].get(i)) \\\n","                      .advance(-8, 'day'), ee.Date.parse('MM/dd/YYYY',site_date_filtered['Date'].get(i)).advance(8, 'day'))).first().divide(16).select(\"Gpp\");\n","   modisevi = MODISEVI.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date_filtered['Date'].get(i)))).first().select(\"EVI\");    \n","   modislst = MODISLST.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date_filtered['Date'].get(i)))).first().select(\"LST_Day_1km\").rename(\"LST\");         \n","   modistree = MODISTree.filterMetadata(\"system:index\", \"contains\", str(site_date_filtered['Water_year'].get(i))).first().select(\"Percent_Tree_Cover\").rename(\"tree\");                                                                \n","   covariates = ee.Image.cat(ppt,Tmean,VPD,modisgpp,modisevi,modisndwi,modislst,modistree)\n","   return covariates;"],"metadata":{"id":"foMXSab3wk77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loop(i):\n"," Cov = ee.ImageCollection([listofimages.get(i)]);\n"," Covimg = Cov.toBands();\n"," ROI_Buffer = geemap.geopandas_to_ee(site_Buffer.iloc[[i]]);\n"," out_stats = os.path.join(out_dir, 'test' + str(i) +'.csv'); \n"," geemap.zonal_statistics(Covimg, ROI_Buffer, out_stats, statistics_type='MEAN', scale=90)"],"metadata":{"id":"28Md_CBPwlvt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k in range (1, 500000, 5000): # Customize the value based on the total record number; set a reasonable step size for intermediate exports\n","  low = k;\n","  high = k+5000 # Set the value to the step size\n","  for j in range (low, high, 5): # Define a step size for processing subsample; smaller value usually corresponds to faster processing but can take more memory space\n","    lb = j;\n","    hb = j+5;\n","    subset = sitedate.filter(ee.Filter.And(ee.Filter.gte('Num', lb),ee.Filter.lt('Num', hb)))\n","    site_date = geemap.ee_to_geopandas(subset, selectors = ['Num','Site','Water_year','Date'])\n","    site_year = geemap.ee_to_geopandas(subset, selectors = ['Num','Site','Water_year'])\n","    site = geemap.ee_to_geopandas(subset, selectors = ['Site', 'Num', 'ID', 'Network', 'Depth', 'Date', 'Water_day', 'Water_year'])\n","    site_buffer = site.buffer(0.0008084837557075693617); #90m \n","    site_Buffer = gpd.GeoDataFrame(geometry=gpd.GeoSeries(site_buffer),crs=\"EPSG:4326\")\n","    ROI_Buffer = geemap.geopandas_to_ee(site_Buffer)\n","    good_list = [] # Get a list of records with values; or else the automatic run can be interrupted\n","    for i in range(0,subset.size().getInfo(),1):\n","      ppt_test = precipitation.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY', site_date['Date'].get(i)))).size().getInfo();\n","      Tmin_test = airTmin.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date['Date'].get(i)))).size().getInfo();\n","      Tmax_test = airTmax.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date['Date'].get(i)))).size().getInfo();\n","      VPD_test = vpd.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date['Date'].get(i)))).size().getInfo();\n","      modisndwi_test = NDWI.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date['Date'].get(i)))).size().getInfo();\n","      modisgpp_test = MODISGPP.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date['Date'].get(i)).advance(-8, 'day'), ee.Date.parse('MM/dd/YYYY',site_date['Date'].get(i)).advance(8, 'day'))).size().getInfo();\n","      modisevi_test = MODISEVI.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date['Date'].get(i)))).size().getInfo();   \n","      modislst_test = MODISLST.filter(ee.Filter.date(ee.Date.parse('MM/dd/YYYY',site_date['Date'].get(i)))).size().getInfo(); \n","      modistree_test = MODISTree.filterMetadata(\"system:index\", \"contains\", str(site_year['Water_year'].get(i))).size().getInfo();   \n","      if (ppt_test != 0) and (Tmin_test != 0) and (Tmax_test != 0) and (VPD_test != 0) and (modisndwi_test != 0) and (modisgpp_test != 0) and (modisevi_test != 0) and (modislst_test != 0) and (modistree_test != 0):\n","        good_list.append(i)\n","    site_date_filtered = site_date[site_date.index.isin(good_list)].reset_index() # Filter out the records without values\n","    merged_col = ee.ImageCollection([])\n","    for i in range(0,len(good_list),1):\n","      col = ee.ImageCollection(Extresult(i))\n","      merged_col = merged_col.merge(col)\n","      listofimages = merged_col.toList(merged_col.size());\n","    for i in range(0,len(good_list),1):\n","      loop(i)\n","    file_list = []\n","    record_list = []\n","    for files in glob.glob(\"test*.csv\"):\n","      file_list.append(files)\n","      file_name_nopath = os.path.basename(files)\n","      file_name = [os.path.splitext(file_name_nopath)[0]]\n","      record_list.append(file_name) \n","    name = pd.DataFrame (record_list, columns = ['File_name'])\n","    result_list = []\n","    for file in file_list:\n","      result = pd.read_csv(file, usecols = [0,1,2,3,4,5,6,7], header = 0)\n","      result.columns = ['ppt', 'Tavg', 'VPD', 'GPP', 'EVI', 'NDWI', 'LST', 'Tree']\n","      result['No']= os.path.basename(file)[4:-4]\n","      siteresult = pd.DataFrame(result)\n","      result_list.append(siteresult)\n","    result = pd.DataFrame(np.concatenate(result_list))\n","    result.columns = ['ppt', 'Tavg', 'VPD', 'GPP', 'EVI', 'NDWI', 'LST', 'Tree', 'No']\n","    site_date_filtered['No'] = site_date_filtered.index\n","    site_date_filtered = pd.DataFrame(site_date_filtered)\n","    site_date_filtered[\"No\"] = site_date_filtered[\"No\"].astype(int)\n","    result[\"No\"] = result[\"No\"].astype(int)\n","    Final_result = site_date_filtered.merge(result, left_on='No', right_on='No')\n","    Final_result.to_csv('Final_result'+ str(j) +'.csv') \n","  Final_list = []\n","  for files in glob.glob(\"Final*.csv\"):\n","    Final_list.append(files)\n","  comb_list = []\n","  for file in Final_list:\n","    comb = pd.read_csv(file)\n","    combresult = pd.DataFrame(comb)\n","    comb_list.append(combresult)\n","  combdata = pd.DataFrame(np.concatenate(comb_list)) \n","  combdata.to_csv('combdata.csv') \n","  !gsutil cp combdata.csv gs://bucket/Moisture/Test/\"covset_\"$j\".csv\" # Customize the output pathway\n","  !rm *.csv "],"metadata":{"id":"SG6-qBrjoZPF"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"7-Colab-Extract-climate-biotic-covariates.ipynb","provenance":[],"mount_file_id":"1vJbJ-4y1UTXh73fNx8FRHhekk3P8oeo1","authorship_tag":"ABX9TyP+/Lv3K2MzWt4PwqBYYCgQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}