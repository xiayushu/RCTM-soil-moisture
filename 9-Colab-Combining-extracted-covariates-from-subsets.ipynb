{"cells":[{"cell_type":"markdown","metadata":{"id":"KyKt9ghcu1lX"},"source":["# Getting started with authentication and package installation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FTHFRdWCu226"},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aYEwJAuMLg0f"},"outputs":[],"source":["!earthengine authenticate\n","import ee\n","ee.Initialize()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUzcfAlQVaxJ"},"outputs":[],"source":["import subprocess\n","try:\n","  import geemap\n","except ImportError:\n","  print('geemap package not installed. Installing ...')\n","  subprocess.check_call([\"python\", '-m', 'pip', 'install', 'geemap'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9jYSc3U5GVj"},"outputs":[],"source":["!pip install geopandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VFb68uSVd6j"},"outputs":[],"source":["#import geemap\n","#import os\n","#import geopandas as gpd\n","import glob\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","source":["# Combine biotic and climate covariates files deposited in Google Cloud bucket"],"metadata":{"id":"R9OgIfI3oMFi"}},{"cell_type":"code","source":["!gsutil cp gs://bucket/Moisture/Test/*.csv . # Import biotic and climate covariates extracted for subsets"],"metadata":{"id":"rHHfIfHu0Sm8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_list = []\n","for files in glob.glob(\"cov*.csv\"):\n","  file_list.append(files)"],"metadata":{"id":"SG6-qBrjoZPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_list = []\n","for file in file_list:\n","  result = pd.read_csv(file, usecols = [3,4,5,6,7,8,10,11,12,13,14,15,16,17], header = 0)\n","  result.columns = ['Coords', 'Date', 'Num', 'Site', 'State', 'Year', 'ppt', 'Tavg', 'VPD', 'GPP', 'EVI', 'NDWI', 'LST', 'Tree']\n","  siteresult = pd.DataFrame(result)\n","  result_list.append(siteresult)\n","  result = pd.DataFrame(np.concatenate(result_list))"],"metadata":{"id":"CtF8L6o41kxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result.to_csv('1_final_result.csv') \n","!gsutil cp 1_final_result.csv gs://bucket/Moisture/Test/\"1_final_result.csv\""],"metadata":{"id":"EG8Xe4MU72T4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Combine NLDAS files deposited in Google Cloud bucket\n","\n"],"metadata":{"id":"sGOJxhyn6Rav"}},{"cell_type":"code","source":["!gsutil cp gs://bucket/Moisture/Test2/*.csv . # Import NLDAS extracted for subsets"],"metadata":{"id":"6I4AZQF_6juM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_list = []\n","for files in glob.glob(\"cov*.csv\"):\n","  file_list.append(files)"],"metadata":{"id":"kUQpWGfW6ugs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_list = []\n","for file in file_list:\n","  result = pd.read_csv(file, usecols = [3,4,5,6,7,8,10,11,12], header = 0)\n","  result.columns = ['Coords', 'Date', 'Num', 'Site', 'State', 'Year', 'NLDAS1', 'NLDAS2', 'NLDAS3']\n","  siteresult = pd.DataFrame(result)\n","  result_list.append(siteresult)\n","  result = pd.DataFrame(np.concatenate(result_list))"],"metadata":{"id":"mJF1M23JGiJz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result.to_csv('1_final_result.csv') \n","!gsutil cp 1_final_result.csv gs://bucket/Moisture/Test2/\"1_final_result.csv\""],"metadata":{"id":"myxkPv1aG7tt"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"9-Colab-Combining-extracted-covariates-from-subsets.ipynb","provenance":[],"mount_file_id":"1vJbJ-4y1UTXh73fNx8FRHhekk3P8oeo1","authorship_tag":"ABX9TyNL+WaZwB1vj5OimVTN5cNC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}